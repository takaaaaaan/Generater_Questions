import cv2
import streamlit as st
import numpy as np
from PIL import Image
from streamlit_webrtc import VideoTransformerBase, webrtc_streamer
import requests
import base64
import openai


# ì´ë¯¸ì§€ì˜ ëª…ì•” ëŒ€ì¡° ì¡°ì •í•˜ê¸°
def adjust_contrast(img, contrast=1.5):
    img = img.astype(np.float32)
    img = img * contrast
    img = np.clip(img, 0, 255)
    return img.astype(np.uint8)


def generate_questions(text, num_questions):
    # ì´ì œ OpenAIë¡œ ì§ˆë¬¸ ìƒì„±ì„ ì‹œì‘í•©ë‹ˆë‹¤ã€‚
    openai.api_key = "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"

    for i in range(num_questions):
        messages = []

        # í…ìŠ¤íŠ¸ì˜ ië²ˆì§¸ ì¤„ì„ ì‚¬ìš©ì ì…ë ¥ìœ¼ë¡œ ì„¤ì •
        user_content = text.split('\n')[i]

        messages.append({"role": "user", "content": f"{user_content}"})

        prompt = f"ì‚¬ìš©ìì˜ í…ìŠ¤íŠ¸ '{user_content}'ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì„ ìƒì„±í•˜ì„¸ìš”."
        messages.append({"role": "system", "content": prompt})

        completion = openai.ChatCompletion.create(model="gpt-3.5-turbo-16k", messages=messages)

        assistant_content = completion.choices[0].message["content"].strip()

        messages.append({"role": "assistant", "content": f"{assistant_content}"})

        st.title(f"âš”ë¬¸ì œ {i+1}âš”")

        st.write(f"{assistant_content}")


class VideoTransformer(VideoTransformerBase):
    def __init__(self):
        self.capture_enabled = False
        self.saved_image = None

    def transform(self, frame):
        img = frame.to_ndarray(format="bgr24")

        # í”Œë˜ê·¸ê°€ í™œì„±í™”ë˜ì—ˆì„ ë•Œ ì´ë¯¸ì§€ ìº¡ì²˜í•˜ê¸°
        if self.capture_enabled:
            self.saved_image = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)
            self.capture_enabled = False

        return img


st.title('ğŸ˜Šë¬¸ì œë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”~!!ğŸ˜Š')

# ì´ë¯¸ì§€ ì†ŒìŠ¤ ì„ íƒ ì˜µì…˜
option = st.selectbox('ì´ë¯¸ì§€ ì†ŒìŠ¤ë¥¼ ì„ íƒí•˜ì„¸ìš”', ('ì´ë¯¸ì§€ ì†ŒìŠ¤ ì„ íƒ', 'ì´ë¯¸ì§€ ì—…ë¡œë“œ', 'ì¹´ë©”ë¼ë¡œ ìº¡ì²˜í•˜ê¸°'))

img = None

if option == 'ì´ë¯¸ì§€ ì—…ë¡œë“œ':
    uploaded_file = st.file_uploader("ì´ë¯¸ì§€ë¥¼ ì„ íƒí•˜ì„¸ìš”...", type="jpg")
    if uploaded_file is not None:
        img = Image.open(uploaded_file)
        img = np.array(img)

elif option == 'ì¹´ë©”ë¼ë¡œ ìº¡ì²˜í•˜ê¸°':
    ctx = webrtc_streamer(key="example", video_transformer_factory=VideoTransformer)

    if st.button('ìº¡ì²˜í•˜ê¸°'):
        ctx.video_transformer.capture_enabled = True
        st.write('ì´ë¯¸ì§€ê°€ ìº¡ì²˜ë˜ì—ˆìŠµë‹ˆë‹¤.')

    if ctx.video_transformer and ctx.video_transformer.saved_image is not None:
        img = ctx.video_transformer.saved_image

# ì´ë¯¸ì§€ê°€ ìˆëŠ” ê²½ìš° OpenCV íš¨ê³¼ ì ìš©
if img is not None:
    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    contrast_img = adjust_contrast(gray_img)

    # ì´ë¯¸ì§€ ì¶œë ¥
    st.image(contrast_img, caption='ì²˜ë¦¬ í›„ ì´ë¯¸ì§€', use_column_width=True)

    # ì´ë¯¸ì§€ ì €ì¥
    cv2.imwrite('processed_image.jpg', contrast_img)

    # ì´ë¯¸ì§€ íŒŒì¼ ì½ê¸°
    with open("processed_image.jpg", "rb") as img_file:
        my_string = base64.b64encode(img_file.read()).decode()

    # ìš”ì²­ í˜ì´ë¡œë“œ ì¤€ë¹„
    request_payload = {
        "requests": [
            {
                "image": {
                    "content": my_string
                },
                "features": [
                    {
                        "type": "TEXT_DETECTION"
                    }
                ]
            }
        ]
    }

    response = requests.post(
        url='https://vision.googleapis.com/v1/images:annotate?key=AIzaSyDAMkNqy8UIL4xN40FbTVE5zYC0ucq8Mtw',
        json=request_payload)

    # ì‘ë‹µì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
    text = response.json()['responses'][0]['fullTextAnnotation']['text']
    st.title("ğŸ“–ì›ë³¸ ë¬¸ì¥ğŸ“–")
    st.write(text)

    # Google Cloud Visionì—ì„œ ì–»ì€ í…ìŠ¤íŠ¸ ì‚¬ìš©
if option == 'ì´ë¯¸ì§€ ì—…ë¡œë“œ' or option == 'ì¹´ë©”ë¼ë¡œ ìº¡ì²˜í•˜ê¸°':
    with st.form(key='question_creation'):
        # "ë¬¸ì œ ìƒì„±" ãƒœã‚¿ãƒ³
        submit_button = st.form_submit_button('ë¬¸ì œ ìƒì„±')
        # Usage
        if submit_button:
            # Google Cloud Visionì—ì„œ ì–»ì€ í…ìŠ¤íŠ¸ ì‚¬ìš©
            if text is not None:
                user_content = text
            else:
                user_content = "ê¸°ë³¸ í…ìŠ¤íŠ¸"  # ë˜ëŠ” ì›í•˜ëŠ” ë‚´ìš©ìœ¼ë¡œ ëŒ€ì²´

            # ë¬¸ì œ ìƒì„±ì„ ì›í•˜ëŠ” íšŸìˆ˜ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤ã€‚
            num_questions = len(text.split('\n')) # í…ìŠ¤íŠ¸ì˜ ì¤„ ìˆ˜ì— ë”°ë¼ ë¬¸ì œì˜ ìˆ˜ë¥¼ ê²°ì •

            generate_questions(user_content, num_questions)